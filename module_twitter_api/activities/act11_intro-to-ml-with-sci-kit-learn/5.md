# 5

If we want to use another classifier, all we need to do is change a few words, here and there.

Let's see this with Decision Tree.

![Image result for decision tree](https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Simple_decision_tree.svg/1131px-Simple_decision_tree.svg.png)

Here is the code to create a Decision Tree classifier.

```python
from sklearn.tree import DecisionTreeClassifier # differnet from SVM

clf = DecisionTreeClassifier() # different from SVM
clf.fit(train_vectors, train_sentiment) # exactly the same as SVM
```

If we want to predict based on our sample review, we can literally copy and paste the code from SVM's prediction, since it is exactly the same

```python
review = "My dog loves this chew bone, it works great!""
sentiment_prediction = clf.predict(review)
print(sentiment_prediction)
```

Here are two more examples for reference:

![Image result for naive bayes](https://upload.wikimedia.org/wikipedia/commons/1/18/Bayes%27_Theorem_MMB_01.jpg)

Naive Bayes:

```python
from sklearn.naive_bayes import GaussianNB

clf = GaussianNB()
clf.fit(train_vectors, train_sentiment)

review = "My dog loves this chew bone, it works great!""
sentiment_prediction = clf.predict(review)
print(sentiment_prediction)
```

![Image result for logistic regression](https://upload.wikimedia.org/wikipedia/commons/6/6d/Exam_pass_logistic_curve.jpeg)

Logistic Regression:

```python
from sklearn.linear_model import LogisticRegression

clf = LogisticRegression()
clf.fit(train_vectors, train_sentiment)

review = "My dog loves this chew bone, it works great!""
sentiment_prediction = clf.predict(review)
print(sentiment_prediction)
```

Wow! It's that easy!

