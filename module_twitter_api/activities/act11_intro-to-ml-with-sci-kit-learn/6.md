# 6

![Close-Up Photo of Dart Pins on Dartboard](https://images.pexels.com/photos/1424745/pexels-photo-1424745.jpeg?auto=compress&cs=tinysrgb&h=750&w=1260)

We can create and predict sentiment using an Sklearn classifier, but how accurate is that prediction?

Let's go back to our SVM classifier

```python
clf = svm.SVC(kernel='linear')
clf.fit(train_vectors, train_sentiment)
```

We can get the average accuracy of the prediction for our test set if we pass in our test data into the classifier's `score` function.

```python
clf.score(test_vectors, test_sentiment) # get the mean accuracy
```

This compares the predicted sentiment value \(given `test_vectors`\) against the actual values, which are stored in `test_sentiment`

Another form of accuracy important in machine learning is f1 score

To get this, we first import the appropriate Sklearn function

```python
from sklearn.metrics import f1_score
```

Then pass in the test set's sentiment values, test set's predicted sentiment, and set the following flags

* average=None to get individual f1\_scores
* labels = \["POSITIVE, "NEUTRAL", "NEGATIVE"\] to specify the labels and the order of the f1 scores returned

```python
f1_score(test_y, clf.predict(test_vectors), average=None, labels=["POSITIVE", "NEUTRAL", "NEGATIVE"])
```

You should get an answer of the form

`array([0.91319444, 0.21052632, 0.22222222])`

The higher the value, the more accurate the prediction was for that label, so

* Positive predictions had an f1 score of 0.91319444 \(the best\)
* Neutral predictions had an f1 score of 0.21052632 \(the worst\)
* Negative predictions had an f1 score of 0.22222222

