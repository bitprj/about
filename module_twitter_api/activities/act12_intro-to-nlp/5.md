# Tokenization

* Tokenzation first breaks up a sentence into words
* Then places a level of importance of each word
* Lastly, produces a description of the input sentence. 

Example of Tokenization:

First, import nltk.

This can be done with

```python
import os
import nltk
import nltk.corpus
```

After we can simply input the command:

```python
print(os.listdir(nltk.data.find("corpora")))
```

Corpora is provided by the package nltk is simply data. When the command is printed, you will see a whole list of files that contain textual data, file names, functions.

