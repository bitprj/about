# Manipulating our Text

Lets look at this giant text block as this is what we will be manipulating.

`word_tokenize` is a tool that we can use that divides our block of text into `tokens` which we will be able to manipulate.

```python
from nltk.tokenize import word_tokenize
AI_tokens = word_tokenize(AI)
AI_tokens
```

Using this block of code, you'll see that the text is split into a bunch of individual strings.

Now we can begin manipulating our block of text. If we wanted to see how often each word appeared, we can use the `FreqDist`

```python
from nltk.probability import FreqDist
fdist = FreqDist()
for word in AI_tokens:
    fdist(word_lower())+=1
fdist
```

By using the FreqDist command, we are able to see how often each word appears.

We can also look at the amount of unique words with the len\(\) command.

Another useful tool that we can use is find the most common words which can be done by:

```python
fdist_top10 = fdist.most_common(10)
fidst_top10
```

As you can see, a lot of using `corpus` is simply knowing how to use different commands which is why it is important to explore the documentation.

